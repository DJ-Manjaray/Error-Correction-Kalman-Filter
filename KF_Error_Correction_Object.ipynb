{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KF_Error_Correction_Object.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvOU2l/RmfLjb2AADV4P0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJ-Manjaray/Error-Correction-Kalman-Filter/blob/master/KF_Error_Correction_Object.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2gRgnnB1L2l"
      },
      "source": [
        "Recursive Algorithm - Kalmna Filter\n",
        "\n",
        "---\n",
        "Using development verrsion of StatsModel\n",
        "There are two versions of Kalman Filter in the StatsModel source.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7d0CGz51LD5",
        "outputId": "0c3acc19-0ac6-45fe-ff55-9c0507ff061f"
      },
      "source": [
        "!git clone https://github.com/DJ-Manjaray/Error-Correction-Kalman-Filter.git\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "path = \"Video/video_randomball.av\"\n",
        "if os.path.exists(path):\n",
        " img = cv2.imread(path)\n",
        " (np.uint8)\n",
        "else:\n",
        " print(\"Path does not exist:\", path)\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Error-Correction-Kalman-Filter' already exists and is not an empty directory.\n",
            "Path does not exist: Video/video_randomball.av\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsVk_Op55Al7"
      },
      "source": [
        "class KalmanFilter(object):\n",
        "    def __init__(self, dt, u_x,u_y, std_acc, x_std_meas, y_std_meas):\n",
        "        \"\"\"\n",
        "        :param dt: sampling time (time for 1 cycle)\n",
        "        :param u_x: acceleration in x-direction\n",
        "        :param u_y: acceleration in y-direction\n",
        "        :param std_acc: process noise magnitude\n",
        "        :param x_std_meas: standard deviation of the measurement in x-direction\n",
        "        :param y_std_meas: standard deviation of the measurement in y-direction\n",
        "        \"\"\"\n",
        "\n",
        "        # Define sampling time\n",
        "        self.dt = dt\n",
        "\n",
        "        # Define the  control input variables\n",
        "        self.u = np.matrix([[u_x],[u_y]])\n",
        "\n",
        "        # Intial State\n",
        "        self.x = np.matrix([[0], [0], [0], [0]])\n",
        "\n",
        "        # Define the State Transition Matrix A\n",
        "        self.A = np.matrix([[1, 0, self.dt, 0],\n",
        "                            [0, 1, 0, self.dt],\n",
        "                            [0, 0, 1, 0],\n",
        "                            [0, 0, 0, 1]])\n",
        "\n",
        "        # Define the Control Input Matrix B\n",
        "        self.B = np.matrix([[(self.dt**2)/2, 0],\n",
        "                            [0,(self.dt**2)/2],\n",
        "                            [self.dt,0],\n",
        "                            [0,self.dt]])\n",
        "\n",
        "        # Define Measurement Mapping Matrix\n",
        "        self.H = np.matrix([[1, 0, 0, 0],\n",
        "                            [0, 1, 0, 0]])\n",
        "\n",
        "        #Initial Process Noise Covariance\n",
        "        self.Q = np.matrix([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n",
        "                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n",
        "                            [(self.dt**3)/2, 0, self.dt**2, 0],\n",
        "                            [0, (self.dt**3)/2, 0, self.dt**2]]) * std_acc**2\n",
        "\n",
        "        #Initial Measurement Noise Covariance\n",
        "        self.R = np.matrix([[x_std_meas**2,0],\n",
        "                           [0, y_std_meas**2]])\n",
        "\n",
        "        #Initial Covariance Matrix\n",
        "        self.P = np.eye(self.A.shape[1])"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qll-y-An5G6j"
      },
      "source": [
        "def predict(self):\n",
        "        \n",
        "        # Update time state\n",
        "        #x_k =Ax_(k-1) + Bu_(k-1)     Eq.(9)\n",
        "        self.x = np.dot(self.A, self.x) + np.dot(self.B, self.u)\n",
        "\n",
        "        # Calculate error covariance\n",
        "        # P= A*P*A' + Q               Eq.(10)\n",
        "        self.P = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q\n",
        "        return self.x[0:2]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tD06RMB5NPQ"
      },
      "source": [
        "def update(self, z):\n",
        "\n",
        "        # S = H*P*H'+R\n",
        "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
        "\n",
        "        # Calculate the Kalman Gain\n",
        "        # K = P * H'* inv(H*P*H'+R)\n",
        "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))  #Eq.(11)\n",
        "\n",
        "        self.x = np.round(self.x + np.dot(K, (z - np.dot(self.H, self.x))))   #Eq.(12)\n",
        "\n",
        "        I = np.eye(self.H.shape[1])\n",
        "\n",
        "        # Update error covariance matrix\n",
        "        self.P = (I - (K * self.H)) * self.P   #Eq.(13)\n",
        "        return self.x[0:2]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c89C6zRd5xVy"
      },
      "source": [
        "def detect(frame,debugMode):\n",
        "    # Convert frame from BGR to GRAY\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    if (debugMode):\n",
        "        cv2.imshow('gray', gray)\n",
        "\n",
        "    # Edge detection using Canny function\n",
        "    img_edges = cv2.Canny(gray,  50, 190, 3)\n",
        "    if (debugMode):\n",
        "        cv2.imshow('img_edges', img_edges)\n",
        "\n",
        "    # Convert to black and white image\n",
        "    ret, img_thresh = cv2.threshold(img_edges, 254, 255,cv2.THRESH_BINARY)\n",
        "    if (debugMode):\n",
        "        cv2.imshow('img_thresh', img_thresh)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Set the accepted minimum & maximum radius of a detected object\n",
        "    min_radius_thresh= 3\n",
        "    max_radius_thresh= 30\n",
        "\n",
        "    centers=[]\n",
        "    for c in contours:\n",
        "        # ref: https://docs.opencv.org/trunk/dd/d49/tutorial_py_contour_features.html\n",
        "        (x, y), radius = cv2.minEnclosingCircle(c)\n",
        "        radius = int(radius)\n",
        "\n",
        "        #Take only the valid circle(s)\n",
        "        if (radius > min_radius_thresh) and (radius < max_radius_thresh):\n",
        "            centers.append(np.array([[x], [y]]))\n",
        "    cv2.imshow('contours', img_thresh)\n",
        "    return centers"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qhyMBY9b6H8k",
        "outputId": "2d60bc03-6299-45a1-fab2-b990d2b77938"
      },
      "source": [
        "def main():\n",
        "\n",
        "\n",
        "    #Variable used to control the speed of reading the video\n",
        "    ControlSpeedVar = 100  #Lowest: 1 - Highest:100\n",
        "\n",
        "    HiSpeed = 100\n",
        "\n",
        "    #Create KalmanFilter object KF\n",
        "    #KalmanFilter(dt, u_x, u_y, std_acc, x_std_meas, y_std_meas)\n",
        "\n",
        "    KF = KalmanFilter(0.1, 1, 1, 1, 0.1,0.1)\n",
        "\n",
        "    debugMode=1\n",
        "\n",
        "    while(True):\n",
        "        # Read frame\n",
        "        ret, frame = VideoCap.read()\n",
        "\n",
        "        # Detect object\n",
        "        centers = detect(frame,debugMode)\n",
        "\n",
        "        # If centroids are detected then track them\n",
        "        if (len(centers) > 0):\n",
        "\n",
        "            # Draw the detected circle\n",
        "            cv2.circle(frame, (int(centers[0][0]), int(centers[0][1])), 10, (0, 191, 255), 2)\n",
        "\n",
        "            # Predict\n",
        "            (x, y) = KF.predict()\n",
        "            # Draw a rectangle as the predicted object position\n",
        "            cv2.rectangle(frame, (x - 15, y - 15), (x + 15, y + 15), (255, 0, 0), 2)\n",
        "\n",
        "            # Update\n",
        "            (x1, y1) = KF.update(centers[0])\n",
        "\n",
        "            # Draw a rectangle as the estimated object position\n",
        "            cv2.rectangle(frame, (x1 - 15, y1 - 15), (x1 + 15, y1 + 15), (0, 0, 255), 2)\n",
        "\n",
        "            cv2.putText(frame, \"Estimated Position\", (x1 + 15, y1 + 10), 0, 0.5, (0, 0, 255), 2)\n",
        "            cv2.putText(frame, \"Predicted Position\", (x + 15, y), 0, 0.5, (255, 0, 0), 2)\n",
        "            cv2.putText(frame, \"Measured Position\", (centers[0][0] + 15, centers[0][1] - 15), 0, 0.5, (0,191,255), 2)\n",
        "\n",
        "        cv2.imshow('image', frame)\n",
        "\n",
        "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
        "            VideoCap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "            break\n",
        "\n",
        "        cv2.waitKey(HiSpeed-ControlSpeedVar+1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # execute main\n",
        "    main()\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-7c89cc3030b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# execute main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-154-7c89cc3030b8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Detect object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebugMode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# If centroids are detected then track them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-153-fb140c5057e8>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(frame, debugMode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebugMode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Convert frame from BGR to GRAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdebugMode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}